{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop=nn.Dropout() #dropout layer\n",
    "        self.fc1=nn.Linear(320,50)\n",
    "        self.fc2=nn.Linear(50,10)\n",
    "         \n",
    "        self.localization=nn.Sequential(nn.Conv2d(1,8,kernel_size=7),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(True),\n",
    "                                        nn.Conv2d(8,10,kernel_size=5),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(True)) #convolutional followed by max pooling and activation function 2x\n",
    "        self.fc_loc=nn.Sequential(nn.Linear(10*3*3,32),\n",
    "                                  nn.ReLU(True),\n",
    "                                  nn.Linear(32,3*2)) #takes output of convolutional layers, reshapes it, passes it through 2 fully connected layers \n",
    "                                                     #to output parameters for the spatial transformation\n",
    "        self.fc_loc[2].weight.data.zero_() #initializes weights of last fully connected layer\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1,0,0,0,1,0])) #initalizes bias of last fully connected layer\n",
    "        \n",
    "    def stn(self,x): #spatial transformer\n",
    "        xs=self.localization(x) #localization network extracts relevant features for the spatial transformation\n",
    "        xs=xs.view(-1,10*3*3) #reshapes\n",
    "        theta=self.fc_loc(xs) #applies fully connected layer to predict parameters for the spatial transformation\n",
    "        theta=theta.view(-1,2,3) #reshapes\n",
    "        grid=F.affine_grid(theta,x.size()) #sampling grid to match coordinates from input image to construct output\n",
    "        x=F.grid_sample(x,grid)\n",
    "        return x\n",
    "    def forward(self,x):\n",
    "        x=self.stn(x)\n",
    "        x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x=x.view(-1,320) #flattened to 1-dimensional tensor\n",
    "        x=self.fc1(x)\n",
    "        x=F.relu(x)\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1) #output tensor containing probabilities for each class\n",
    "    \n",
    "net=Net().to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,target=next(iter(train_loader))\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.01)\n",
    "t_loss = []\n",
    "acc = []\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        data,target=data.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=net(data)\n",
    "        loss=F.nll_loss(output,target)\n",
    "        loss.backward() #computes gradients of loss\n",
    "        optimizer.step() #updates model parameters\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        test_loss=0\n",
    "        correct=0\n",
    "        for data,target in test_loader:\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            output=net(data)\n",
    "            test_loss+=F.nll_loss(output,target,size_average=False).item()\n",
    "            pred=output.max(1,keepdim=True)[1] #obtain predicted class label\n",
    "            correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss/=len(test_loader.dataset)\n",
    "        t_loss.append(test_loss)\n",
    "        acc.append(correct/len(test_loader.dataset))\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
